{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f01fc08-85b7-4d34-b125-8f5758158547",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b00c1-359d-48f7-9a7a-82e37a8446d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56640f3-f861-4f22-bb97-fc7bebe0463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22689d4d-542c-4083-8e6b-7bc98e96f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55f194-3f54-44f9-9006-eafb2d1d136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa533195-632c-449e-a8b9-9dc2adbed33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))  # 0 for the first device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24e104-2648-48a7-bdfb-93732c46fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    properties = torch.cuda.get_device_properties(0)\n",
    "    print(\"Device name:\", properties.name)\n",
    "    print(\"Total memory:\", properties.total_memory//1024//1024//1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea763b-5b72-42a8-904b-1fa02257cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062b42c-7626-4402-b89e-e800e03e2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3) ## CHANGE DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94759-86bb-4aa9-89e1-fe7f89cacc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a30134-2a6a-4a12-92ca-73245d4ffe6a",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n",
    "The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
    "\n",
    "Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d41f7-2015-41d0-bf94-e9cf417b98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working with tensors, similar to tensorflow\n",
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe4ddc-ea3f-4a3a-8f88-ff8f92d62863",
   "metadata": {},
   "source": [
    "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "* `torch.zeros`: Creates a tensor filled with zeros\n",
    "* `torch.ones`: Creates a tensor filled with ones\n",
    "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
    "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b71b0-ad3c-4324-aefa-10e226563ddc",
   "metadata": {},
   "source": [
    "#### Tensor to Numpy, and Numpy to Tensor\n",
    "\n",
    "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475bd96-c08e-4fb8-b0c3-6304732cd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a81dbe-b43a-417d-99ee-29499b650dcb",
   "metadata": {},
   "source": [
    "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80be3b-9eef-424b-baae-ba4d146ae366",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa57b9-96b6-41d0-8065-7f1e20eb8838",
   "metadata": {},
   "source": [
    "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU . In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7bd5a-c288-450d-9040-66f12c7d813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Move to GPU device\n",
    "tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553538e-b6d6-4496-aa96-1cb6404b7875",
   "metadata": {},
   "source": [
    "#### Operations\n",
    "\n",
    "Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n",
    "\n",
    "The simplest operation is to add two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03a066-0f4d-4931-8dfd-854584df66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "y = x1 + x2\n",
    "\n",
    "print(\"X1\", x1)\n",
    "print(\"X2\", x2)\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77338f-ce6d-43ba-8667-33975d9f96af",
   "metadata": {},
   "source": [
    "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416f3a1-5fe1-4573-9b97-b606960ea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "print(\"X1 (before)\", x1)\n",
    "print(\"X2 (before)\", x2)\n",
    "\n",
    "x2.add_(x1)\n",
    "print(\"X1 (after)\", x1)\n",
    "print(\"X2 (after)\", x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e34a0-a989-407e-b4a7-d1b85c96aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparison CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb7bc2-d039-4b83-83d4-06d004d165ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5000, 5000)\n",
    "\n",
    "## CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "\n",
    "## GPU version\n",
    "x = x.to(device)\n",
    "_ = torch.matmul(x, x)  # First operation to 'burn in' GPU\n",
    "# CUDA is asynchronous, so we need to use different timing functions\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "_ = torch.matmul(x, x)\n",
    "end.record()\n",
    "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94c402-a009-4a50-a039-20a39d503656",
   "metadata": {},
   "source": [
    "### Dynamic Computation Graph and Backpropagation\n",
    "\n",
    "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
    "\n",
    "If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**. It's a more general term.\n",
    "\n",
    "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input. \n",
    "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
    "\n",
    "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**. \n",
    "\n",
    "> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
    "\n",
    "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495245f-c35c-4826-bde5-76b5afad0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a3399-fbdb-4da1-97ad-d62cf2fffd6b",
   "metadata": {},
   "source": [
    "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286ee3c-71c9-433d-a1f6-ca79e74197f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a1b16-f3ae-4a64-a385-727ec9537b89",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14636fa-0159-4185-a65a-1c655e5e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547f247-5654-4d86-a9ef-43f09df6eccd",
   "metadata": {},
   "source": [
    "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
    "\n",
    "$$y = \\frac{1}{\\ell(x)}\\sum_i \\left[(x_i + 2)^2 + 3\\right],$$\n",
    "\n",
    "where we use $\\ell(x)$ to denote the number of elements in $x$. In other words, we are taking a mean here over the operation within the sum. You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664be833-71a5-49b0-95b0-6e70ad79f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23c0a9-36e8-46e6-9744-a4499c25fada",
   "metadata": {},
   "source": [
    "We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834915b-ab5a-4206-a8a7-cff073aea84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712e5c50-cc95-4386-8a0d-13aa595e1eb9",
   "metadata": {},
   "source": [
    "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91592e8f-af58-4495-b8e6-7100cd00ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f2a98-3b9a-4757-b2a4-1a1ea3cc4f8e",
   "metadata": {},
   "source": [
    "## Data Example, in comparison with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e40842-1396-4360-a20c-ab3da7114c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight','Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,na_values='?', comment='\\t',sep=' ', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6e75b-d401-4d1a-a6fa-b6c200759215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad0c48-a51b-42eb-a738-4244a7bed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12d78d-d081-4efd-9ce7-ad48dc00d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe48bf8-4221-4545-97f5-837839954e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e353a3e-b667-4475-b875-ca927da3bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844cb2c-5589-42ec-9f58-2b09a1374877",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ba94b-1e34-41be-b8e7-36efcb4b3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_dataset[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cdaaa-fc29-43db-8846-228cb03b1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import torch utilities\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f455b-782d-4878-a555-983fde583c56",
   "metadata": {},
   "source": [
    "The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc. A full list can be found [here](https://pytorch.org/docs/stable/nn.html). In case you need a certain network layer, check the documentation of the package first before writing the layer yourself as the package likely contains the code for it already. We import it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0c039-1a49-4b6e-8e36-3ba017763f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "#train_features = train_dataset.copy()\n",
    "#test_features = test_dataset.copy()\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')\n",
    "#train_features = train_features['Horsepower']\n",
    "#test_features = test_features['Horsepower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc718e-fad0-4f66-a4dc-1babb7c7b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs\n",
    "class Normalize:\n",
    "    def __init__(self, features):\n",
    "        features = torch.tensor(features, dtype=torch.float32)  # Convert to tensor\n",
    "        self.mean = torch.mean(features, dim=0)\n",
    "        self.std = torch.std(features, dim=0)\n",
    "\n",
    "    def __call__(self, features):\n",
    "        features = torch.tensor(features, dtype=torch.float32)  # Convert to tensor\n",
    "        return (features - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1770d1-6b91-4338-be87-0900188461c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca232a-7408-4eff-aadc-d97eb327d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_features.values.astype(float)\n",
    "y_train = train_labels.values.astype(float)\n",
    "X_test = test_features.values.astype(float)\n",
    "y_test = test_labels.values.astype(float)\n",
    "##\n",
    "#X_train = X_train.reshape(-1,1)\n",
    "#X_test = X_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a01a71-a7f6-4384-a889-7de878adf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003a41d-1aae-44b6-959a-7673212685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalizer.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f91b8-6f59-408a-820d-61715db33233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_normalized = normalizer(X_train)\n",
    "#X_test_normalized = normalizer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca6508-a66d-47a3-82f3-a58e590fb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CarDataset(data.Dataset):\n",
    "    def __init__(self, features, targets, normalizer):\n",
    "        self.features = normalizer(features)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443219d1-8dd8-4f46-8388-b93005828647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and DataLoader\n",
    "dataset_train = CarDataset(X_train, y_train, normalizer)\n",
    "dataloader_train = data.DataLoader(dataset_train, batch_size=8, shuffle=True, drop_last=False)\n",
    "\n",
    "# Example usage\n",
    "#for batch_features, batch_targets in dataloader:\n",
    "#    print(\"Batch features:\", batch_features)\n",
    "#    print(\"Batch targets:\", batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642b164-4a39-4c90-828a-d9dddc40260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)   # Dense layer with hidden_dim units\n",
    "        self.act_fn = nn.ReLU() ## Activation\n",
    "        self.output = nn.Linear(hidden_dim1, 1)# Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x) \n",
    "        x = self.act_fn(x) # Apply activation\n",
    "        x = self.output(x)                     # Output layer (no activation for regression)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9a8e0-8f95-4ae4-ac66-4a886fb80f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(X_train.shape[1],40)\n",
    "print(model)\n",
    "model.to(device)\n",
    "#push model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720268a-02c7-439c-bff2-238ca6fba695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbce65-72c8-47c7-8282-e4671302ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8398f19-0f69-4066-a0a2-2b61b33bca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = nn.L1Loss() ## Mean Absolute Error (nn.MSELoss --> Mean squared error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652101a6-6309-437d-a9c5-2fde29d2bad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d288b-6073-47ce-abdc-a98610267988",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = 'runs/experiments/pt'\n",
    "writer = SummaryWriter(logging_dir)\n",
    "model_plotted = False\n",
    "model.train()\n",
    "# Train the model\n",
    "epochs = 100\n",
    "error = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_features, batch_targets in dataloader_train:\n",
    "        # push data to device\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "        # For the very first batch, we visualize the computation graph in TensorBoard\n",
    "        if not model_plotted:\n",
    "            writer.add_graph(model, batch_features)\n",
    "            model_plotted = True\n",
    "        # Forward pass\n",
    "        predictions = model(batch_features)\n",
    "        loss = loss_module(predictions.squeeze(), batch_targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "      # Add average loss to TensorBoard\n",
    "    epoch_loss /= len(dataloader_train)\n",
    "    writer.add_scalar('training_loss',\n",
    "                      epoch_loss,\n",
    "                      global_step = epoch + 1)\n",
    "\n",
    "\n",
    "    writer.close()\n",
    "    error.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2306f-478b-4138-be0b-2079ce9d9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error, label='loss')\n",
    "plt.ylim([0, 10])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf988e8-6cd9-4acd-9f13-a58f192513a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    xx = torch.from_numpy(np.linspace(0.0, 250, 251).reshape(-1,1))\n",
    "    xx = xx.to(torch.float32)\n",
    "    xx = normalizer(xx)\n",
    "    xx = xx.to(device)\n",
    "    model.eval()\n",
    "    yy = model(xx).squeeze()\n",
    "    yf = yy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4498c-0a9f-4224-bb7a-e20f295a8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    xf = np.linspace(0.0, 250, 251)\n",
    "    plt.scatter(train_features, train_labels, label='Data')\n",
    "    plt.plot(xf, yf, color='k', label='Predictions')\n",
    "    plt.xlabel('Horsepower')\n",
    "    plt.ylabel('MPG')\n",
    "    plt.xlim(0,250)\n",
    "    plt.ylim(0,50)\n",
    "    plt.legend()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538cb36-bcee-46e4-bece-0657cc98fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict = model.state_dict()\n",
    "#print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be3091-0f7c-43bf-8517-c42dd347b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(state_dict, \"our_model.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52980d6a-0d4c-4e9c-bbb3-eff26cd1b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state dict from the disk (make sure it is the same name as above)\n",
    "#state_dict = torch.load(\"our_model.tar\")\n",
    "\n",
    "# Create a new model and load the state\n",
    "#new_model = SimpleNN(X_train.shape[1], 32)\n",
    "#new_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4bcb3-09d1-4e1f-b234-e97ea06bd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25621ce8-dd2a-43b5-adf4-4f6b1800376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and DataLoader for test set\n",
    "dataset_test = CarDataset(X_test, y_test, normalizer)\n",
    "dataloader_test = data.DataLoader(dataset_test, batch_size=100, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0d2c9-5c2d-408b-bfb6-b3bebbb01ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_targets in dataloader_test:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "        preds = model(batch_features)\n",
    "        preds = preds.squeeze()\n",
    "        loss = loss_module(preds, batch_targets)\n",
    "print('Model MAE (loss) = {:.4}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12643531-fe3a-43df-830e-cecc802784e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =  preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475212d0-d95b-4a6b-bd3b-ca37f60727db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa127727-6f9e-4c03-a324-63e619e9b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = predictions - y_test\n",
    "plt.hist(error, bins=25)\n",
    "plt.xlabel('Prediction Error [MPG]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e685c36-a1ce-440c-8277-916232664749",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "TODO: Repeat the analysis for the same architecture as shown in the `tf_example.ipynb` for the `Horsepower` only and all 9 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee06c9-47bd-495c-ba4e-542ff680ebff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9f3dc-be77-4c0b-8009-d54e09451585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e7653-57b5-4325-af5e-e7170f0560c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed60df53-f04b-4be6-88ed-bb6e060659a5",
   "metadata": {},
   "source": [
    "## References\n",
    "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html\n",
    "https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545724f5-ae11-4634-9e9d-44aaf02b2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995d72e-38b8-40b7-afc7-6344f65c32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir runs/experiments --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ff7cb-6d85-4400-83bc-210693c1700a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
